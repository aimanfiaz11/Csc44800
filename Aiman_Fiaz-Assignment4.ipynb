{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44b943d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f15f477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d714ec3d",
   "metadata": {},
   "source": [
    "### Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c37e1974",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=load_iris()\n",
    "X=data.data\n",
    "y=data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4369979a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06ea3bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8b4f0b",
   "metadata": {},
   "source": [
    "### About dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f05602e",
   "metadata": {},
   "source": [
    "The above dataset contains the information about three species(['setosa', 'versicolor', 'virginica']) of iris flower. Each data point conatins four features('sepal length (cm)', 'sepal width (cm)', 'petal length (cm)','petal width (cm)') of a single specicies. We have to predict the species name using these four features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313d97be",
   "metadata": {},
   "source": [
    "### Split dataset into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "45608fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X,test_X,train_y,test_y=train_test_split(X,y,test_size=0.25,random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842c7b3f",
   "metadata": {},
   "source": [
    "### Let's scale our dataset inorder to get a better performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "73ecaecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc=StandardScaler()\n",
    "sc.fit(train_X,train_y)\n",
    "train_X=sc.transform(train_X)\n",
    "test_X=sc.transform(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9ca3f8",
   "metadata": {},
   "source": [
    "### Let's apply logisitic Regression algorith with default parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca00df04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr=LogisticRegression()\n",
    "lr.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74945304",
   "metadata": {},
   "source": [
    "make prediction on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e4a47ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=lr.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e2ca5688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the algorithm on train set  0.9553571428571429\n",
      "Accuracy of the algorithm on test set 0.9473684210526315\n",
      "Classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       0.90      0.90      0.90        10\n",
      "           2       0.93      0.93      0.93        14\n",
      "\n",
      "    accuracy                           0.95        38\n",
      "   macro avg       0.94      0.94      0.94        38\n",
      "weighted avg       0.95      0.95      0.95        38\n",
      " \n",
      "\n",
      "Confusion matrix \n",
      " [[14  0  0]\n",
      " [ 0  9  1]\n",
      " [ 0  1 13]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of the algorithm on train set \",accuracy_score(train_y,lr.predict(train_X)))\n",
    "print(\"Accuracy of the algorithm on test set\",accuracy_score(test_y,pred))\n",
    "print(\"Classification report \\n\",classification_report(test_y,pred),\"\\n\")\n",
    "print(\"Confusion matrix \\n\",confusion_matrix(test_y,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791b147e",
   "metadata": {},
   "source": [
    "### Let's apply SVM algorithm on this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "da135b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf=SVC()\n",
    "svm_clf.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05256c4",
   "metadata": {},
   "source": [
    "make prediction on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "82a1bdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=svm_clf.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1320154a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the algorithm on train set  0.9821428571428571\n",
      "Accuracy of the algorithm on test set 0.9736842105263158\n",
      "Classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       0.91      1.00      0.95        10\n",
      "           2       1.00      0.93      0.96        14\n",
      "\n",
      "    accuracy                           0.97        38\n",
      "   macro avg       0.97      0.98      0.97        38\n",
      "weighted avg       0.98      0.97      0.97        38\n",
      " \n",
      "\n",
      "Confusion matrix \n",
      " [[14  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  1 13]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of the algorithm on train set \",accuracy_score(train_y,svm_clf.predict(train_X)))\n",
    "print(\"Accuracy of the algorithm on test set\",accuracy_score(test_y,pred))\n",
    "print(\"Classification report \\n\",classification_report(test_y,pred),\"\\n\")\n",
    "print(\"Confusion matrix \\n\",confusion_matrix(test_y,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0e7e09",
   "metadata": {},
   "source": [
    "### Let's apply KNearest Neighbors algorithm on this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d992cce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn=KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76e7f13",
   "metadata": {},
   "source": [
    "make prediction on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38e350fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=knn.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54e53656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the algorithm on train set  0.9732142857142857\n",
      "Accuracy of the algorithm on test set 0.9736842105263158\n",
      "Classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       0.91      1.00      0.95        10\n",
      "           2       1.00      0.93      0.96        14\n",
      "\n",
      "    accuracy                           0.97        38\n",
      "   macro avg       0.97      0.98      0.97        38\n",
      "weighted avg       0.98      0.97      0.97        38\n",
      " \n",
      "\n",
      "Confusion matrix \n",
      " [[14  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  1 13]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of the algorithm on train set \",accuracy_score(train_y,knn.predict(train_X)))\n",
    "print(\"Accuracy of the algorithm on test set\",accuracy_score(test_y,pred))\n",
    "print(\"Classification report \\n\",classification_report(test_y,pred),\"\\n\")\n",
    "print(\"Confusion matrix \\n\",confusion_matrix(test_y,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08e7757",
   "metadata": {},
   "source": [
    "### Let's apply neural network on this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28643ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(max_iter=500)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_clf=MLPClassifier(max_iter=500)\n",
    "neural_clf.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04af9a3d",
   "metadata": {},
   "source": [
    "make prediction on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4cd8b72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=neural_clf.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3dcae272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the algorithm on train set  0.9821428571428571\n",
      "Accuracy of the algorithm on test set 0.9473684210526315\n",
      "Classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       0.90      0.90      0.90        10\n",
      "           2       0.93      0.93      0.93        14\n",
      "\n",
      "    accuracy                           0.95        38\n",
      "   macro avg       0.94      0.94      0.94        38\n",
      "weighted avg       0.95      0.95      0.95        38\n",
      " \n",
      "\n",
      "Confusion matrix \n",
      " [[14  0  0]\n",
      " [ 0  9  1]\n",
      " [ 0  1 13]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of the algorithm on train set \",accuracy_score(train_y,neural_clf.predict(train_X)))\n",
    "print(\"Accuracy of the algorithm on test set\",accuracy_score(test_y,pred))\n",
    "print(\"Classification report \\n\",classification_report(test_y,pred),\"\\n\")\n",
    "print(\"Confusion matrix \\n\",confusion_matrix(test_y,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51d38f5",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bd0156",
   "metadata": {},
   "source": [
    "By applying LogisticRegression, Support Vector Machine, Knearestneighbors and neural netwrok algorithms, It has been observed that out of all algorithsm , KNN and SVM performed equally well on test set, only SVM has a little high score on train set. Hence it is overfitting a bit on train set. Hence KNN with 5 nearest neighbors is best for our use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346d2fa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
